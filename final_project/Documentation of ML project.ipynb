{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation of Intro to Machine Learning Project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "\n",
    "### Task 1: Select what features you'll use.\n",
    "features_list = ['poi','salary'] \n",
    "\n",
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "\n",
    "### Task 2: Remove outliers\n",
    "\n",
    "### Task 3: Create new feature(s)\n",
    "\n",
    "### Store to my_dataset for easy export below.\n",
    "my_dataset = data_dict\n",
    "\n",
    "### Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "### Task 4: Try a varity of classifiers\n",
    "\n",
    "# Provided to give you a starting point. Try a variety of classifiers.\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "\n",
    "### Task 5: Tune your classifier to achieve better than .3 precision and recall \n",
    "\n",
    "# Example starting point. Try investigating other evaluation techniques!\n",
    "from sklearn.cross_validation import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Summarize for us the goal of this project and how machine learning is useful in trying to accomplish it. As part of your answer, give some background on the dataset and how it can be used to answer the project question. Were there any outliers in the data when you got it, and how did you handle those?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The goal of this project is to build a person of interest identifier based on financial and email data made public as a result of the Enron scandal. And machine learning can be useful in this case because it can detect hidden patterns in the data using its features better than humans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In 2000, Enron was one of the largest companies in the United States. By 2002, it had collapsed into bankruptcy due to widespread corporate fraud. The key people of the scancal were Jeff Skilling, Kenneth Lay and Andrew Fastow. Jeff Skilling was the chairman of the Enron board of directors. Kenneth Lay was the CEO of Enron during most of the time that fraud was being perpetrated. Andrew Fastow was CFO (chief financial officer) of Enron during most of the time that fraud was going on. They were sentenced to imprisonment. We can know whether the identifier can detect POIs well by seeing that they were detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of data points: 146\n",
      "Total number of features: 21\n",
      "\n",
      "The allocation across classes(POI/non-POI):\n",
      "False    128\n",
      "True      18\n",
      "Name: poi, dtype: int64\n",
      "The proportion of POI: 0.123\n",
      "\n",
      "The number of NaNs in each feature:\n",
      "loan_advances                142\n",
      "director_fees                129\n",
      "restricted_stock_deferred    128\n",
      "deferral_payments            107\n",
      "deferred_income               97\n",
      "long_term_incentive           80\n",
      "bonus                         64\n",
      "from_this_person_to_poi       60\n",
      "from_poi_to_this_person       60\n",
      "from_messages                 60\n",
      "shared_receipt_with_poi       60\n",
      "to_messages                   60\n",
      "other                         53\n",
      "expenses                      51\n",
      "salary                        51\n",
      "exercised_stock_options       44\n",
      "restricted_stock              36\n",
      "email_address                 35\n",
      "total_payments                21\n",
      "total_stock_value             20\n",
      "poi                            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Data exploration.\n",
    "#Show the most important characteristics of the dataset\n",
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "    \n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data_dict).T\n",
    "\n",
    "#get total number of data points, total number of features\n",
    "num_datapoints = df.shape[0]\n",
    "num_features = df.shape[1]\n",
    "print \"Total number of data points:\", num_datapoints\n",
    "print \"Total number of features:\", num_features\n",
    "print \"\" #insert blank line\n",
    "\n",
    "#show the allocation across classes(POI/non-POI)\n",
    "poi_allocation = df.poi.value_counts()\n",
    "print \"The allocation across classes(POI/non-POI):\"\n",
    "print poi_allocation\n",
    "print \"The proportion of POI:\", round(poi_allocation.loc[True] / float(df.poi.count()) * 100, 3), \"%\"\n",
    "print \"\" #insert blank line\n",
    "\n",
    "#show how many NaNs in each feature\n",
    "num_NaN_in_each_feature = (df == 'NaN').sum()\n",
    "print \"The number of NaNs in each feature:\"\n",
    "print num_NaN_in_each_feature.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What features did you end up using in your POI identifier, and what selection process did you use to pick them? Did you have to do any scaling? Why or why not? As part of the assignment, you should attempt to engineer your own feature that does not come ready-made in the dataset -- explain what feature you tried to make, and the rationale behind it. (You do not necessarily have to use it in the final analysis, only engineer and test it.) In your feature selection step, if you used an algorithm like a decision tree, please also give the feature importances of the features that you use, and if you used an automated feature selection function like SelectKBest, please report the feature scores and reasons for your choice of parameter values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. What algorithm did you end up using? What other one(s) did you try? How did model performance differ between algorithms? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. What does it mean to tune the parameters of an algorithm, and what can happen if you don’t do this well?  How did you tune the parameters of your particular algorithm? What parameters did you tune? (Some algorithms do not have parameters that you need to tune -- if this is the case for the one you picked, identify and briefly explain how you would have done it for the model that was not your final choice or a different model that does utilize parameter tuning, e.g. a decision tree classifier). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. What is validation, and what’s a classic mistake you can make if you do it wrong? How did you validate your analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Give at least 2 evaluation metrics and your average performance for each of them.  Explain an interpretation of your metrics that says something human-understandable about your algorithm’s performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
