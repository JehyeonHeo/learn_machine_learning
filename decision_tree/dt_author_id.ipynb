{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JehyeonHeo\\Anaconda3\\envs\\py27\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of Chris training emails: 7936\n",
      "no. of Sara training emails: 7884\n"
     ]
    }
   ],
   "source": [
    "# %load dt_author_id.py\n",
    "#!/usr/bin/python\n",
    "\n",
    "\"\"\" \n",
    "    This is the code to accompany the Lesson 3 (decision tree) mini-project.\n",
    "\n",
    "    Use a Decision Tree to identify emails from the Enron corpus by author:    \n",
    "    Sara has label 0\n",
    "    Chris has label 1\n",
    "\"\"\"\n",
    "    \n",
    "import sys\n",
    "from time import time\n",
    "sys.path.append(\"..\\\\tools\\\\\")\n",
    "from email_preprocess import preprocess\n",
    "from sklearn import tree\n",
    "\n",
    "### features_train and features_test are the features for the training\n",
    "### and testing datasets, respectively\n",
    "### labels_train and labels_test are the corresponding item labels\n",
    "features_train, features_test, labels_train, labels_test = preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 72.679 s\n",
      "predicting time: 0.162 s\n",
      "accuracy: 0.977246871445\n"
     ]
    }
   ],
   "source": [
    "#########################################################\n",
    "### your code goes here ###\n",
    "\n",
    "#first, I'm going to designate min_samples_split = 40.\n",
    "clf = tree.DecisionTreeClassifier(min_samples_split = 40)\n",
    "\n",
    "t0 = time()\n",
    "clf.fit(features_train, labels_train)\n",
    "print \"training time:\", round(time()-t0, 3), \"s\"\n",
    "\n",
    "t1 = time()\n",
    "clf.predict(features_train, labels_train)\n",
    "print \"predicting time:\", round(time()-t1, 3), \"s\"\n",
    "\n",
    "print \"accuracy:\", clf.score(features_test, labels_test)\n",
    "\n",
    "#########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features: 3785\n"
     ]
    }
   ],
   "source": [
    "#see how many features in the data.\n",
    "print \"number of features:\", len(features_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " no. of Chris training emails: 7936\n",
      "no. of Sara training emails: 7884\n",
      "training time when percentile was changed to 1: 4.954 s\n",
      "predicting time when percentile was changed to 1: 0.019 s\n",
      "accuracy when percentile was changed to 1: 0.967007963595\n"
     ]
    }
   ],
   "source": [
    "#########################################################\n",
    "### your code goes here ###\n",
    "\n",
    "#rerun after email_preprocess_1.py was made.:\n",
    "#selector = SelectPercentile(f_classif, percentile=1)\n",
    "#percentile was changed from 10 to 1.\n",
    "from email_preprocess_1 import preprocess_1\n",
    "\n",
    "features_train_1, features_test_1, labels_train_1, labels_test_1 = preprocess_1()\n",
    "\n",
    "clf_percentile_1 = tree.DecisionTreeClassifier(min_samples_split = 40)\n",
    "\n",
    "t0_percentile_1 = time()\n",
    "clf_percentile_1.fit(features_train_1, labels_train_1)\n",
    "print \"training time when percentile was changed to 1:\", round(time()-t0_percentile_1, 3), \"s\"\n",
    "\n",
    "t1_percentile_1 = time()\n",
    "clf_percentile_1.predict(features_train_1, labels_train_1)\n",
    "print \"predicting time when percentile was changed to 1:\", round(time()-t1_percentile_1, 3), \"s\"\n",
    "\n",
    "print \"accuracy when percentile was changed to 1:\", clf_percentile_1.score(features_test_1, labels_test_1)\n",
    "\n",
    "#########################################################\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features when percentile = 1: 379\n"
     ]
    }
   ],
   "source": [
    "#see how many features in the data when the percentile was changed.\n",
    "print \"number of features when percentile = 1:\", len(features_train_1[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
